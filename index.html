<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ONNX Model Inference</title>
</head>
<body>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <script>
        async function main() {
            try {
                const session = await ort.InferenceSession.create('./model.onnx');

                const video = document.createElement('video');
                video.autoplay = true;

                // Access the webcam
                if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
                    navigator.mediaDevices.getUserMedia({ video: true })
                        .then(function (stream) {
                            video.srcObject = stream;
                        })
                        .catch(function (error) {
                            document.write(`Error accessing the webcam: ${error}`);
                        });
                } else {
                    document.write("getUserMedia is not supported in this browser.");
                }

                const canvas = document.createElement('canvas');
                canvas.width = 128;
                canvas.height = 128;
                const context = canvas.getContext('2d');

                video.addEventListener('play', async function () {
                    const intervalId = setInterval(async function () {
                        context.drawImage(video, 0, 0, 128, 128);
                        const imageData = context.getImageData(0, 0, 128, 128);

                        // Create a tensor from the image data
                        const data = new Float32Array(imageData.data).map(v => v / 255); // Normalize
                        const tensor = new ort.Tensor('float32', data, [1, 128, 128, 4]); // Adjust the last dimension to match the number of channels

                        // Feed input and run
                        const results = await session.run({ input: tensor });

                        // Process results as needed
                        const outputData = results.output.data;
                        document.write(`Output data: ${outputData}`);

                    }, 100); // Adjust interval as needed

                    // Stop the interval when the video stops
                    video.addEventListener('ended', function () {
                        clearInterval(intervalId);
                    });
                });

                document.body.appendChild(video);
                document.body.appendChild(canvas);

            } catch (error) {
                document.write(`Failed to inference ONNX model: ${error}.`);
            }
        }

        main();
    </script>
</body>
</html>
